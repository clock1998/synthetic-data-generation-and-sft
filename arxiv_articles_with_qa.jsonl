{"text": "<|system|>You are a helpful academic Q&A assistant specialized in scholarly content.<|user|>What is the name of the full-spectrum benchmark introduced in the article for evaluating the fidelity of generated world models in embodied AI?<|assistant|>WorldLens"}
{"text": "<|system|>You are a helpful academic Q&A assistant specialized in scholarly content.<|user|>What are the five aspects covered by the WorldLens benchmark for evaluating world models?<|assistant|>Generation, Reconstruction, Action-Following, Downstream Task, and Human Preference"}
{"text": "<|system|>You are a helpful academic Q&A assistant specialized in scholarly content.<|user|>What is the purpose of WorldLens-26K dataset according to the article?<|assistant|>WorldLens-26K is a large-scale dataset of human-annotated videos with numerical scores and textual rationales, constructed to align objective metrics with human judgment"}
{"text": "<|system|>You are a helpful academic Q&A assistant specialized in scholarly content.<|user|>What is the role of WorldLens-Agent in the WorldLens ecosystem according to the article?<|assistant|>WorldLens-Agent is an evaluation model distilled from the annotations in the WorldLens-26K dataset, enabling scalable, explainable scoring"}
{"text": "<|system|>You are a helpful academic Q&A assistant specialized in scholarly content.<|user|>What is the significance of the WorldLens benchmark, dataset, and agent according to the article?<|assistant|>The benchmark, dataset, and agent form a unified ecosystem for measuring world fidelity \u2013 standardizing how future models are judged not only by how real they look, but by how real they behave"}
{"text": "<|system|>You are a helpful academic Q&A assistant specialized in scholarly content.<|user|>What is the main focus of the research presented in this paper?<|assistant|>The paper presents a navigation system, StereoWalker, that augments foundation models for robot navigation with stereo inputs and explicit mid-level vision such as depth estimation and dense pixel tracking."}
{"text": "<|system|>You are a helpful academic Q&A assistant specialized in scholarly content.<|user|>Why does the paper argue that relying solely on monocular vision for robot navigation is inefficient?<|assistant|>The paper argues that relying solely on monocular vision is inefficient because it requires large amounts of pixel-to-action supervision, and it cannot provide precise geometric and dynamic understanding in dynamic and unstructured settings due to depth-scale ambiguity in monocular views."}
{"text": "<|system|>You are a helpful academic Q&A assistant specialized in scholarly content.<|user|>What benefits does the use of stereo vision provide in the context of the StereoWalker system?<|assistant|>Stereo vision resolves the depth-scale ambiguity and provides higher navigation performance in the StereoWalker system."}
{"text": "<|system|>You are a helpful academic Q&A assistant specialized in scholarly content.<|user|>How does the performance of StereoWalker compare to the state-of-the-art navigation systems in terms of training data requirement?<|assistant|>StereoWalker achieves a comparable performance as the state-of-the-art using only 1.5% of the training data."}
{"text": "<|system|>You are a helpful academic Q&A assistant specialized in scholarly content.<|user|>What is the significance of the research in terms of real-world applications?<|assistant|>The research has the potential to enable direct, end-to-end deployment for real-world applications such as last mile delivery."}
